{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5aa873-0e72-4585-8036-66cae09b0c51",
   "metadata": {},
   "source": [
    "# 4. Train a Neural Network and Log to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04cb897c-605a-40fa-8e5f-842bb4d70b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e14588f-39a6-4f6e-93c9-1ff43802d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data to the range [0, 1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a04ce1-13e8-4b26-b598-009fd932f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(28, 28)),    # Explicit Input Layer\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a534a28d-e55c-4fc0-bc09-ac188390b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the log directory for TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ad9380-6a24-476a-950b-8ddeeb6304d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8717 - loss: 0.4376 - val_accuracy: 0.9642 - val_loss: 0.1208\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.1044 - val_accuracy: 0.9721 - val_loss: 0.0903\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.0676 - val_accuracy: 0.9718 - val_loss: 0.0923\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0489 - val_accuracy: 0.9771 - val_loss: 0.0835\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0378 - val_accuracy: 0.9731 - val_loss: 0.0892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fcba904c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for 5 epochs with TensorBoard callback\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aae532c-31c4-4a01-a47a-bbddca17c40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ba9f990de133770e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ba9f990de133770e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9721c-391f-4f49-9af1-9667d97b7091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47d7d73d-4e05-4b46-89ce-745db825503d",
   "metadata": {},
   "source": [
    "#                                                 Questions and Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f2b06b-87ff-4e45-80cc-2a211bf12c61",
   "metadata": {},
   "source": [
    "# 4.1 What patterns do you observe in the training and validation accuracy curves?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8f0c1-62dc-4553-a4fb-6fb44d3602c9",
   "metadata": {},
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486fd6c-4d72-4d7d-b430-7b8a409ad319",
   "metadata": {},
   "source": [
    "Patterns in Training and Validation Accuracy Curves\n",
    " \n",
    "When looking at the training and validation accuracy curves, you’ll often see that both start low and gradually increase as the model learns from the data. The training accuracy usually improves faster since the model is directly learning from that data. If the validation accuracy follows a similar trend, it means the model is generalizing well. However, if there’s a noticeable gap—where training accuracy keeps improving but validation accuracy plateaus or drops—it’s a sign that the model might be overfitting, meaning it's memorizing the training data instead of learning patterns that generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4da978-5bac-4fff-9ad3-0dc8dfa98a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6cf5cc0-62bf-4b23-bce5-4b17ab53a0d8",
   "metadata": {},
   "source": [
    "# 4.2 How can you use TensorBoard to detect overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625d943-4a12-489b-842e-a0ce35afbe46",
   "metadata": {},
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb3a5f-5923-4bb3-9165-1bfc0684d2b5",
   "metadata": {},
   "source": [
    "You can detect overfitting in TensorBoard by comparing the training and validation curves. If you notice that the training accuracy keeps going up while the validation accuracy stays the same or starts to decrease, that’s a strong sign of overfitting. Similarly, if the training loss keeps decreasing but the validation loss starts increasing, the model is likely overfitting. TensorBoard makes it easy to spot these trends visually, which helps you decide when to adjust your model or stop training early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0958db-be9c-48c0-bbee-e829fb9c93c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd4fa13c-8dfe-444e-b219-ed698f88c1ed",
   "metadata": {},
   "source": [
    "# 4.3 What happens when you increase the number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23327c6-8e48-4738-ac35-a95f70777e44",
   "metadata": {},
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f48f7-846b-42dd-863d-ed59a4dcbddc",
   "metadata": {},
   "source": [
    "When you increase the number of epochs, the model continues to learn from the training data. This usually leads to higher training accuracy, but after a certain point, the model might start overfitting—where it performs well on training data but poorly on validation data. This happens because the model starts memorizing details and noise from the training set instead of learning general patterns. As a result, validation accuracy may stop improving and even start to decline. To prevent this, techniques like early stopping, regularization, or using more data can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87e0f9-ccba-41fd-82d6-3e760518594b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce5d4f-5fcd-400f-9095-f65f4b017528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
